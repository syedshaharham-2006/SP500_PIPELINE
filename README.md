## ğŸŒ S&P 500 Real-Time Data Pipeline
An automated ETL pipeline designed to pull, process, and store real-time intraday data for the S&P 500 index. This pipeline leverages Apache Airflow running in Docker to fetch 1-minute interval stock data from Yahoo Finance, processes it for analysis, and stores it in Amazon S3 and Snowflake for further visualization and exploration. ğŸ“Šâ„ï¸

ğŸ“– Table of Contents

â€¢ Project Overview
â€¢ Tech Stack
â€¢ Prerequisites

# Setup

ğŸ³ Docker Setup
âš™ï¸ Airflow Setup

How to Use

ğŸ” Automation
ğŸ“Š Monitoring
ğŸ’¾ Data Outputs
ğŸ’¡ Contributing
ğŸ“œ License

# ğŸš€ Project Overview

This project orchestrates an ETL pipeline using Apache Airflow for pulling, transforming, and loading S&P 500 intraday data.
Workflow Breakdown:

 â€¢ Extract: Retrieves 1-minute interval data for the top 10 S&P 500 stocks via yfinance.
 â€¢ Transform: Adds new metrics like minute returns and trading hours for analysis.
 â€¢ Load: Pushes the processed data into Amazon S3 and Snowflake for future analysis and reporting.
 â€¢  All tasks are executed within Dockerized Airflow containers, ensuring a reproducible and isolated environment. ğŸ§©

# ğŸ§° Tech Stack

Tools

ğŸ³ Apache Airflow	Workflow orchestration & scheduling
ğŸ‹ Docker / Docker Compose	Containerization & environment management
ğŸ“Š yfinance	Fetching real-time stock market data
ğŸ§¹ pandas	Data cleaning & transformation
â˜ï¸ Amazon S3	Cloud storage for data storage
â„ï¸ Snowflake	Data warehousing and analytics
ğŸ Python 3.x	Primary programming language
ğŸ”§ Prerequisites

Before setting up, ensure you have the following:
âœ… Docker & Docker Compose - Install Docker
âœ… Python 3.x
âœ… AWS Account - S3 credentials for storage
âœ… Snowflake Account - Database access credentials
âœ… Git - To clone the repository

